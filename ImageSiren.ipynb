{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "from dataset import PixelDataset\n",
    "from net import GradientUtils, ImageSiren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406ec42",
   "metadata": {},
   "source": [
    "# Loading Grayscale image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce04345",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = plt.imread(\"facade.png\")\n",
    "img = 2 * (img_ - 0.5) # standartization of data (-1,+1)\n",
    "downsampling_factor = 8\n",
    "img = img[::downsampling_factor, ::downsampling_factor] # reducing image resolution by skipping pixel rows and cols\n",
    "size = img.shape[0]\n",
    "dataset = PixelDataset(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2fd51",
   "metadata": {},
   "source": [
    "# Hyperparameters settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ac022",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 301\n",
    "batch_size = int(size ** 2)\n",
    "logging_freq = 20\n",
    "\n",
    "model_name = \"mlp_relu\"  # \"siren\", \"mlp_relu\"\n",
    "hidden_features = 256\n",
    "hidden_layers = 3\n",
    "\n",
    "target = \"intensity\"  # \"intensity\", \"grad\", \"laplace\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf890b",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"siren\":\n",
    "    model = ImageSiren(\n",
    "        hidden_features,\n",
    "        hidden_layers=hidden_layers,\n",
    "        hidden_omega=30,\n",
    "    )\n",
    "elif model_name == \"mlp_relu\":\n",
    "    layers = [Linear(2, hidden_features), ReLU()]\n",
    "\n",
    "    for _ in range(hidden_layers):\n",
    "        layers.append(Linear(hidden_features, hidden_features))\n",
    "        layers.append(ReLU())\n",
    "\n",
    "    layers.append(Linear(hidden_features, 1))\n",
    "\n",
    "    model = Sequential(*layers)\n",
    "\n",
    "    for module in model.modules():\n",
    "        if not isinstance(module, Linear):\n",
    "            continue\n",
    "        torch.nn.init.xavier_normal_(module.weight)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported model\")\n",
    "    \n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "optim = torch.optim.Adam(lr=1e-4, params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403f804",
   "metadata": {},
   "source": [
    "# Training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9b54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(n_epochs):\n",
    "    losses = []\n",
    "    for d_batch in tqdm.tqdm(dataloader):\n",
    "        x_batch = d_batch[\"coords\"].to(torch.float32)\n",
    "        x_batch.requires_grad = True\n",
    "\n",
    "        y_true_batch = d_batch[\"intensity\"].to(torch.float32)\n",
    "        y_true_batch = y_true_batch[:, None]\n",
    "\n",
    "        y_pred_batch = model(x_batch)\n",
    "\n",
    "        if target == \"intensity\":\n",
    "            loss = ((y_true_batch - y_pred_batch) ** 2).mean()\n",
    "\n",
    "        elif target == \"grad\":\n",
    "            y_pred_g_batch = GradientUtils.gradient(y_pred_batch, x_batch)\n",
    "            y_true_g_batch = d_batch[\"grad\"].to(torch.float32)\n",
    "            loss = ((y_true_g_batch - y_pred_g_batch) ** 2).mean()\n",
    "\n",
    "        elif target == \"laplace\":\n",
    "            y_pred_l_batch = GradientUtils.laplace(y_pred_batch, x_batch)\n",
    "            y_true_l_batch = d_batch[\"laplace\"].to(torch.float32)[:, None]\n",
    "            loss = ((y_true_l_batch - y_pred_l_batch) ** 2).mean()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized target\")\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    print(e, np.mean(losses))\n",
    "\n",
    "    if e % logging_freq == 0:\n",
    "        pred_img = np.zeros_like(img)\n",
    "        pred_img_grad_norm = np.zeros_like(img)\n",
    "        pred_img_laplace = np.zeros_like(img)\n",
    "\n",
    "        orig_img = np.zeros_like(img)\n",
    "        for d_batch in tqdm.tqdm(dataloader):\n",
    "            coords = d_batch[\"coords\"].to(torch.float32)\n",
    "            coords.requires_grad = True\n",
    "            coords_abs = d_batch[\"coords_abs\"].numpy()\n",
    "\n",
    "            pred = model(coords)\n",
    "            pred_n = pred.detach().numpy().squeeze()\n",
    "            pred_g = (\n",
    "                GradientUtils.gradient(pred, coords)\n",
    "                .norm(dim=-1)\n",
    "                .detach()\n",
    "                .numpy()\n",
    "                .squeeze()\n",
    "            )\n",
    "            pred_l = GradientUtils.laplace(pred, coords).detach().numpy().squeeze()\n",
    "\n",
    "            pred_img[coords_abs[:, 0], coords_abs[:, 1]] = pred_n\n",
    "            pred_img_grad_norm[coords_abs[:, 0], coords_abs[:, 1]] = pred_g\n",
    "            pred_img_laplace[coords_abs[:, 0], coords_abs[:, 1]] = pred_l\n",
    "\n",
    "        fig, axs = plt.subplots(3, 2, constrained_layout=True)\n",
    "        axs[0, 0].imshow(dataset.img, cmap=\"gray\")\n",
    "        axs[0, 1].imshow(pred_img, cmap=\"gray\")\n",
    "\n",
    "        axs[1, 0].imshow(dataset.grad_norm, cmap=\"gray\")\n",
    "        axs[1, 1].imshow(pred_img_grad_norm, cmap=\"gray\")\n",
    "\n",
    "        axs[2, 0].imshow(dataset.laplace, cmap=\"gray\")\n",
    "        axs[2, 1].imshow(pred_img_laplace, cmap=\"gray\")\n",
    "\n",
    "        for row in axs:\n",
    "            for ax in row:\n",
    "                ax.set_axis_off()\n",
    "\n",
    "        fig.suptitle(f\"Iteration: {e}\")\n",
    "        axs[0, 0].set_title(\"Ground truth\")\n",
    "        axs[0, 1].set_title(\"Prediction\")\n",
    "\n",
    "        plt.savefig(f\"visualization/{e}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13922c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "images = []\n",
    "for e in range(n_epochs):\n",
    "    if e % logging_freq == 0:\n",
    "        images.append(imageio.imread(f\"visualization/{e}.png\"))\n",
    "imageio.mimsave('visualization/MLPRELU.gif', images,  fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbbd01",
   "metadata": {},
   "source": [
    "<img src=\"./facade.gif\" width=\"750\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c002994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_learning",
   "language": "python",
   "name": "pytorch_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
